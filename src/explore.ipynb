{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'pandas'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, GridSearchCV\n",
                        "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import pickle\n",
                "import os\n",
                "\n",
                "# Set a random seed for reproducibility across all steps\n",
                "RANDOM_STATE = 42\n",
                "TEST_SIZE = 0.2\n",
                "\n",
                "print(\"Starting Random Forest Diabetes Prediction Project...\\n\")\n",
                "\n",
                "# --- Step 1: Loading the dataset ---\n",
                "print(\"--- Step 1: Loading the dataset ---\")\n",
                "# Assuming 'diabetes_processed.csv' is in the root directory where the script is run\n",
                "# If it's in a 'data/processed/' folder, adjust the path: 'data/processed/diabetes_processed.csv'\n",
                "file_path = 'diabetes_processed.csv' # Or 'data/processed/diabetes_processed.csv' if structured that way\n",
                "\n",
                "try:\n",
                "    df_processed = pd.read_csv(file_path)\n",
                "    # Assuming 'Outcome' is your target variable for diabetes prediction\n",
                "    X = df_processed.drop('Outcome', axis=1)\n",
                "    y = df_processed['Outcome']\n",
                "\n",
                "    # Splitting the dataset into training and testing sets\n",
                "    # Using random_state for reproducibility, and stratify=y for balanced classes\n",
                "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y)\n",
                "    print(\"Dataset loaded and split successfully.\")\n",
                "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
                "    print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
                "\n",
                "except FileNotFoundError:\n",
                "    print(f\"Error: The file '{file_path}' was not found. Please ensure it's in the correct directory (e.g., in 'data/processed/').\")\n",
                "    print(\"Exiting. Please place your 'diabetes_processed.csv' file correctly.\")\n",
                "    exit() # Exit if the data isn't found\n",
                "\n",
                "# Display first few rows of training data to confirm\n",
                "print(\"\\nX_train head:\")\n",
                "print(X_train.head())\n",
                "print(\"\\ny_train value counts:\")\n",
                "print(y_train.value_counts(normalize=True))\n",
                "\n",
                "# --- Step 2: Build a random forest ---\n",
                "print(\"\\n--- Step 2: Building and Optimizing a Random Forest ---\")\n",
                "\n",
                "# --- 2a. Train a baseline Random Forest model ---\n",
                "print(\"\\n2a. Training a Baseline Random Forest Model:\")\n",
                "rf_baseline = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1) # n_jobs=-1 uses all CPU cores\n",
                "rf_baseline.fit(X_train, y_train)\n",
                "\n",
                "y_pred_baseline = rf_baseline.predict(X_test)\n",
                "accuracy_baseline = accuracy_score(y_test, y_pred_baseline)\n",
                "\n",
                "print(f\"Baseline Random Forest Accuracy: {accuracy_baseline:.4f}\")\n",
                "print(\"\\nBaseline Classification Report:\")\n",
                "print(classification_report(y_test, y_pred_baseline))\n",
                "print(\"\\nBaseline Confusion Matrix:\")\n",
                "print(confusion_matrix(y_test, y_pred_baseline))\n",
                "\n",
                "# --- 2b. Experiment with hyperparameters and analyze impact ---\n",
                "print(\"\\n2b. Experimenting with Hyperparameters:\")\n",
                "\n",
                "# Experiment with n_estimators\n",
                "n_estimators_values = [50, 100, 200, 300, 400, 500]\n",
                "accuracy_n_estimators = []\n",
                "\n",
                "print(\"\\nTesting different n_estimators values:\")\n",
                "for n_est in n_estimators_values:\n",
                "    print(f\"  Training with n_estimators={n_est}...\")\n",
                "    rf_model = RandomForestClassifier(n_estimators=n_est, random_state=RANDOM_STATE, n_jobs=-1)\n",
                "    rf_model.fit(X_train, y_train)\n",
                "    y_pred = rf_model.predict(X_test)\n",
                "    acc = accuracy_score(y_test, y_pred)\n",
                "    accuracy_n_estimators.append(acc)\n",
                "    print(f\"    Accuracy: {acc:.4f}\")\n",
                "\n",
                "# Plotting the impact of n_estimators\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(n_estimators_values, accuracy_n_estimators, marker='o')\n",
                "plt.title('Random Forest Accuracy vs. Number of Estimators')\n",
                "plt.xlabel('Number of Estimators (n_estimators)')\n",
                "plt.ylabel('Accuracy')\n",
                "plt.grid(True)\n",
                "plt.xticks(n_estimators_values)\n",
                "plt.savefig('rf_accuracy_n_estimators.png') # Save plot for analysis\n",
                "plt.show() # Display the plot\n",
                "plt.close() # Close the plot to free memory\n",
                "\n",
                "# Experiment with max_depth\n",
                "# Use a fixed n_estimators for consistency, e.g., 200 based on common practice or initial n_estimators plot insights\n",
                "max_depth_values = [None, 5, 10, 15, 20, 25] # None means unlimited depth\n",
                "accuracy_max_depth = []\n",
                "\n",
                "print(\"\\nTesting different max_depth values:\")\n",
                "for max_d in max_depth_values:\n",
                "    print(f\"  Training with max_depth={max_d}...\")\n",
                "    rf_model = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, max_depth=max_d, n_jobs=-1)\n",
                "    rf_model.fit(X_train, y_train)\n",
                "    y_pred = rf_model.predict(X_test)\n",
                "    acc = accuracy_score(y_test, y_pred)\n",
                "    accuracy_max_depth.append(acc)\n",
                "    print(f\"    Accuracy: {acc:.4f}\")\n",
                "\n",
                "# Plotting the impact of max_depth\n",
                "plt.figure(figsize=(10, 6))\n",
                "# Plotting against index to handle 'None' on the x-axis properly with custom labels\n",
                "plt.plot(range(len(max_depth_values)), accuracy_max_depth, marker='o')\n",
                "plt.title('Random Forest Accuracy vs. Max Depth')\n",
                "plt.xlabel('Max Depth (max_depth)')\n",
                "plt.ylabel('Accuracy')\n",
                "plt.grid(True)\n",
                "plt.xticks(range(len(max_depth_values)), labels=[str(d) if d is not None else 'None' for d in max_depth_values]) # Set custom xticks\n",
                "plt.savefig('rf_accuracy_max_depth.png') # Save plot\n",
                "plt.show() # Display the plot\n",
                "plt.close() # Close the plot\n",
                "\n",
                "# --- 2c. More Systematic Hyperparameter Tuning with GridSearchCV ---\n",
                "print(\"\\n2c. More Systematic Hyperparameter Tuning with GridSearchCV:\")\n",
                "# Define a parameter grid based on your exploration and common practices\n",
                "param_grid = {\n",
                "    'n_estimators': [100, 200, 300], # Refined based on n_estimators plot\n",
                "    'max_depth': [5, 10, 15, None],  # Refined based on max_depth plot\n",
                "    'min_samples_split': [2, 5, 10], # Common values to explore\n",
                "    'min_samples_leaf': [1, 2, 4]    # Common values to explore\n",
                "}\n",
                "\n",
                "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=RANDOM_STATE),\n",
                "                           param_grid=param_grid,\n",
                "                           cv=5, # 5-fold cross-validation\n",
                "                           n_jobs=-1, # Use all available cores\n",
                "                           scoring='accuracy', # Optimize for accuracy\n",
                "                           verbose=2) # Verbose output to see progress\n",
                "\n",
                "grid_search.fit(X_train, y_train)\n",
                "\n",
                "print(f\"\\nBest parameters found by GridSearchCV: {grid_search.best_params_}\")\n",
                "print(f\"Best cross-validation accuracy on training set (GridSearchCV): {grid_search.best_score_:.4f}\")\n",
                "\n",
                "# Get the best estimator from GridSearchCV\n",
                "rf_best_model = grid_search.best_estimator_\n",
                "\n",
                "# Evaluate the best model on the unseen test set\n",
                "y_pred_best = rf_best_model.predict(X_test)\n",
                "final_accuracy_best_grid = accuracy_score(y_test, y_pred_best)\n",
                "\n",
                "print(f\"\\nFinal Random Forest Accuracy on Test Set (with best GridSearchCV params): {final_accuracy_best_grid:.4f}\")\n",
                "print(\"\\nFinal Classification Report (Best Model):\")\n",
                "print(classification_report(y_test, y_pred_best))\n",
                "print(\"\\nFinal Confusion Matrix (Best Model):\")\n",
                "print(confusion_matrix(y_test, y_pred_best))\n",
                "\n",
                "# --- Step 3: Save the model ---\n",
                "print(\"\\n--- Step 3: Saving the Model ---\")\n",
                "models_dir = 'models'\n",
                "os.makedirs(models_dir, exist_ok=True) # Create the 'models' directory if it doesn't exist\n",
                "\n",
                "model_filename = os.path.join(models_dir, 'random_forest_diabetes_model.pkl')\n",
                "\n",
                "try:\n",
                "    with open(model_filename, 'wb') as file:\n",
                "        pickle.dump(rf_best_model, file)\n",
                "    print(f\"Model successfully saved to: {model_filename}\")\n",
                "except Exception as e:\n",
                "    print(f\"Error saving model: {e}\")\n",
                "\n",
                "print(\"\\nRandom Forest Diabetes Prediction Project Completed.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
